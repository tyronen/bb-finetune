{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1dc63a5",
   "metadata": {},
   "source": [
    "### Define dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932f4c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np  # or jax.numpy as jnp if needed\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "class TLDRDataset:\n",
    "    def __init__(self, data_dir, tokenizer, split, max_length=550):\n",
    "        \"\"\"\n",
    "        Load TLDR dataset from local parquet files.\n",
    "        \n",
    "        Args:\n",
    "            data_dir: Path to directory containing parquet files\n",
    "            tokenizer: Tokenizer to use\n",
    "            split: 'train', 'valid', or 'test'\n",
    "            max_length: Maximum sequence length\n",
    "        \"\"\"\n",
    "        # Load the parquet file\n",
    "        parquet_file = Path(data_dir) / f\"tldr_{split}.parquet\"\n",
    "        if not parquet_file.exists():\n",
    "            raise FileNotFoundError(f\"Dataset file not found: {parquet_file}\")\n",
    "        \n",
    "        df = pd.read_parquet(parquet_file)\n",
    "        \n",
    "        # Combine prompt and label for training (teacher forcing)\n",
    "        self.examples = [row[\"prompt\"] + row[\"label\"] for _, row in df.iterrows()]\n",
    "        \n",
    "        # Limit validation set size for faster iteration\n",
    "        if \"valid\" in split:\n",
    "            self.examples = self.examples[:2000]\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        print(f\"Loaded {len(self.examples)} examples from {parquet_file}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Tokenize the text\n",
    "        enc = self.tokenizer(\n",
    "            self.examples[idx],\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": np.array(enc[\"input_ids\"], dtype=np.int32),\n",
    "            \"attention_mask\": np.array(enc[\"attention_mask\"], dtype=np.int32),\n",
    "            \"labels\": np.array(enc[\"input_ids\"], dtype=np.int32),  # teacher forcing\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43e3ab9",
   "metadata": {},
   "source": [
    "### Load model and tokeniser\n",
    "Stick to gpt2 now for compatibility, then move to qwen. GPT2 = 124m params, 500mb. qwen0.6b = 550m params, 2gb. So beware 3x qwen0.6b on my 8gb gpu might tank its memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22f82951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, FlaxAutoModelForCausalLM\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# 1. Tokenizer is identical\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 2. Load the Flax (JAX) model\n",
    "#    .from_pretrained returns a FlaxAutoModelForCausalLM whose weights live in model.params\n",
    "model = FlaxAutoModelForCausalLM.from_pretrained(\"gpt2\", dtype=jnp.float32)\n",
    "\n",
    "# 3. If you‚Äôve added new tokens, resize just like in PyTorch:\n",
    "#    model = model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# 4. Make sure padding is configured\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# 5. Pull out the parameter dict for training\n",
    "params = model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089f812e",
   "metadata": {},
   "source": [
    "### Inspect model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d4f9d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç JAX/Flax Model Inspection\n",
      "==================================================\n",
      "Model type: <class 'transformers.models.gpt2.modeling_flax_gpt2.FlaxGPT2LMHeadModel'>\n",
      "Model config: GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.53.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "Vocab size: 50257\n",
      "Hidden size: 768\n",
      "Number of layers: 12\n",
      "Number of attention heads: 12\n",
      "\n",
      "üìä Parameter Analysis\n",
      "==============================\n",
      "Total parameters: 124,439,808\n",
      "Total parameters (millions): 124.44M\n",
      "\n",
      "üèóÔ∏è Parameter Structure\n",
      "=========================\n",
      "transformer.h.0.attn.c_attn.bias: (2304,) (float32)\n",
      "transformer.h.0.attn.c_attn.kernel: (2304, 768) (float32)\n",
      "transformer.h.0.attn.c_proj.bias: (768,) (float32)\n",
      "transformer.h.0.attn.c_proj.kernel: (768, 768) (float32)\n",
      "transformer.h.0.ln_1.bias: (768,) (float32)\n",
      "transformer.h.0.ln_1.scale: (768,) (float32)\n",
      "transformer.h.0.ln_2.bias: (768,) (float32)\n",
      "transformer.h.0.ln_2.scale: (768,) (float32)\n",
      "transformer.h.0.mlp.c_fc.bias: (3072,) (float32)\n",
      "transformer.h.0.mlp.c_fc.kernel: (3072, 768) (float32)\n",
      "transformer.h.0.mlp.c_proj.bias: (768,) (float32)\n",
      "transformer.h.0.mlp.c_proj.kernel: (768, 3072) (float32)\n",
      "transformer.h.1.attn.c_attn.bias: (2304,) (float32)\n",
      "transformer.h.1.attn.c_attn.kernel: (2304, 768) (float32)\n",
      "transformer.h.1.attn.c_proj.bias: (768,) (float32)\n",
      "transformer.h.1.attn.c_proj.kernel: (768, 768) (float32)\n",
      "transformer.h.1.ln_1.bias: (768,) (float32)\n",
      "transformer.h.1.ln_1.scale: (768,) (float32)\n",
      "transformer.h.1.ln_2.bias: (768,) (float32)\n",
      "transformer.h.1.ln_2.scale: (768,) (float32)\n",
      "transformer.h.1.mlp.c_fc.bias: (3072,) (float32)\n",
      "transformer.h.1.mlp.c_fc.kernel: (3072, 768) (float32)\n",
      "transformer.h.1.mlp.c_proj.bias: (768,) (float32)\n",
      "transformer.h.1.mlp.c_proj.kernel: (768, 3072) (float32)\n",
      "transformer.h.10.attn.c_attn.bias: (2304,) (float32)\n",
      "transformer.h.10.attn.c_attn.kernel: (2304, 768) (float32)\n",
      "transformer.h.10.attn.c_proj.bias: (768,) (float32)\n",
      "transformer.h.10.attn.c_proj.kernel: (768, 768) (float32)\n",
      "transformer.h.10.ln_1.bias: (768,) (float32)\n",
      "transformer.h.10.ln_1.scale: (768,) (float32)\n",
      "transformer.h.10.ln_2.bias: (768,) (float32)\n",
      "transformer.h.10.ln_2.scale: (768,) (float32)\n",
      "transformer.h.10.mlp.c_fc.bias: (3072,) (float32)\n",
      "transformer.h.10.mlp.c_fc.kernel: (3072, 768) (float32)\n",
      "transformer.h.10.mlp.c_proj.bias: (768,) (float32)\n",
      "transformer.h.10.mlp.c_proj.kernel: (768, 3072) (float32)\n",
      "transformer.h.11.attn.c_attn.bias: (2304,) (float32)\n",
      "transformer.h.11.attn.c_attn.kernel: (2304, 768) (float32)\n",
      "transformer.h.11.attn.c_proj.bias: (768,) (float32)\n",
      "transformer.h.11.attn.c_proj.kernel: (768, 768) (float32)\n",
      "transformer.h.11.ln_1.bias: (768,) (float32)\n",
      "transformer.h.11.ln_1.scale: (768,) (float32)\n",
      "transformer.h.11.ln_2.bias: (768,) (float32)\n",
      "transformer.h.11.ln_2.scale: (768,) (float32)\n",
      "transformer.h.11.mlp.c_fc.bias: (3072,) (float32)\n",
      "transformer.h.11.mlp.c_fc.kernel: (3072, 768) (float32)\n",
      "transformer.h.11.mlp.c_proj.bias: (768,) (float32)\n",
      "transformer.h.11.mlp.c_proj.kernel: (768, 3072) (float32)\n",
      "transformer.h.2.attn.c_attn.bias: (2304,) (float32)\n",
      "transformer.h.2.attn.c_attn.kernel: (2304, 768) (float32)\n",
      "transformer.h.2.attn.c_proj.bias: (768,) (float32)\n",
      "transformer.h.2.attn.c_proj.kernel: (768, 768) (float32)\n",
      "transformer.h.2.ln_1.bias: (768,) (float32)\n",
      "transformer.h.2.ln_1.scale: (768,) (float32)\n",
      "transformer.h.2.ln_2.bias: (768,) (float32)\n",
      "transformer.h.2.ln_2.scale: (768,) (float32)\n",
      "transformer.h.2.mlp.c_fc.bias: (3072,) (float32)\n",
      "transformer.h.2.mlp.c_fc.kernel: (3072, 768) (float32)\n",
      "transformer.h.2.mlp.c_proj.bias: (768,) (float32)\n",
      "transformer.h.2.mlp.c_proj.kernel: (768, 3072) (float32)\n",
      "transformer.h.3.attn.c_attn.bias: (2304,) (float32)\n",
      "transformer.h.3.attn.c_attn.kernel: (2304, 768) (float32)\n",
      "transformer.h.3.attn.c_proj.bias: (768,) (float32)\n",
      "transformer.h.3.attn.c_proj.kernel: (768, 768) (float32)\n",
      "transformer.h.3.ln_1.bias: (768,) (float32)\n",
      "transformer.h.3.ln_1.scale: (768,) (float32)\n",
      "transformer.h.3.ln_2.bias: (768,) (float32)\n",
      "transformer.h.3.ln_2.scale: (768,) (float32)\n",
      "transformer.h.3.mlp.c_fc.bias: (3072,) (float32)\n",
      "transformer.h.3.mlp.c_fc.kernel: (3072, 768) (float32)\n",
      "transformer.h.3.mlp.c_proj.bias: (768,) (float32)\n",
      "transformer.h.3.mlp.c_proj.kernel: (768, 3072) (float32)\n",
      "transformer.h.4.attn.c_attn.bias: (2304,) (float32)\n",
      "transformer.h.4.attn.c_attn.kernel: (2304, 768) (float32)\n",
      "transformer.h.4.attn.c_proj.bias: (768,) (float32)\n",
      "transformer.h.4.attn.c_proj.kernel: (768, 768) (float32)\n",
      "transformer.h.4.ln_1.bias: (768,) (float32)\n",
      "transformer.h.4.ln_1.scale: (768,) (float32)\n",
      "transformer.h.4.ln_2.bias: (768,) (float32)\n",
      "transformer.h.4.ln_2.scale: (768,) (float32)\n",
      "transformer.h.4.mlp.c_fc.bias: (3072,) (float32)\n",
      "transformer.h.4.mlp.c_fc.kernel: (3072, 768) (float32)\n",
      "transformer.h.4.mlp.c_proj.bias: (768,) (float32)\n",
      "transformer.h.4.mlp.c_proj.kernel: (768, 3072) (float32)\n",
      "transformer.h.5.attn.c_attn.bias: (2304,) (float32)\n",
      "transformer.h.5.attn.c_attn.kernel: (2304, 768) (float32)\n",
      "transformer.h.5.attn.c_proj.bias: (768,) (float32)\n",
      "transformer.h.5.attn.c_proj.kernel: (768, 768) (float32)\n",
      "transformer.h.5.ln_1.bias: (768,) (float32)\n",
      "transformer.h.5.ln_1.scale: (768,) (float32)\n",
      "transformer.h.5.ln_2.bias: (768,) (float32)\n",
      "transformer.h.5.ln_2.scale: (768,) (float32)\n",
      "transformer.h.5.mlp.c_fc.bias: (3072,) (float32)\n",
      "transformer.h.5.mlp.c_fc.kernel: (3072, 768) (float32)\n",
      "transformer.h.5.mlp.c_proj.bias: (768,) (float32)\n",
      "transformer.h.5.mlp.c_proj.kernel: (768, 3072) (float32)\n",
      "transformer.h.6.attn.c_attn.bias: (2304,) (float32)\n",
      "transformer.h.6.attn.c_attn.kernel: (2304, 768) (float32)\n",
      "transformer.h.6.attn.c_proj.bias: (768,) (float32)\n",
      "transformer.h.6.attn.c_proj.kernel: (768, 768) (float32)\n",
      "transformer.h.6.ln_1.bias: (768,) (float32)\n",
      "transformer.h.6.ln_1.scale: (768,) (float32)\n",
      "transformer.h.6.ln_2.bias: (768,) (float32)\n",
      "transformer.h.6.ln_2.scale: (768,) (float32)\n",
      "transformer.h.6.mlp.c_fc.bias: (3072,) (float32)\n",
      "transformer.h.6.mlp.c_fc.kernel: (3072, 768) (float32)\n",
      "transformer.h.6.mlp.c_proj.bias: (768,) (float32)\n",
      "transformer.h.6.mlp.c_proj.kernel: (768, 3072) (float32)\n",
      "transformer.h.7.attn.c_attn.bias: (2304,) (float32)\n",
      "transformer.h.7.attn.c_attn.kernel: (2304, 768) (float32)\n",
      "transformer.h.7.attn.c_proj.bias: (768,) (float32)\n",
      "transformer.h.7.attn.c_proj.kernel: (768, 768) (float32)\n",
      "transformer.h.7.ln_1.bias: (768,) (float32)\n",
      "transformer.h.7.ln_1.scale: (768,) (float32)\n",
      "transformer.h.7.ln_2.bias: (768,) (float32)\n",
      "transformer.h.7.ln_2.scale: (768,) (float32)\n",
      "transformer.h.7.mlp.c_fc.bias: (3072,) (float32)\n",
      "transformer.h.7.mlp.c_fc.kernel: (3072, 768) (float32)\n",
      "transformer.h.7.mlp.c_proj.bias: (768,) (float32)\n",
      "transformer.h.7.mlp.c_proj.kernel: (768, 3072) (float32)\n",
      "transformer.h.8.attn.c_attn.bias: (2304,) (float32)\n",
      "transformer.h.8.attn.c_attn.kernel: (2304, 768) (float32)\n",
      "transformer.h.8.attn.c_proj.bias: (768,) (float32)\n",
      "transformer.h.8.attn.c_proj.kernel: (768, 768) (float32)\n",
      "transformer.h.8.ln_1.bias: (768,) (float32)\n",
      "transformer.h.8.ln_1.scale: (768,) (float32)\n",
      "transformer.h.8.ln_2.bias: (768,) (float32)\n",
      "transformer.h.8.ln_2.scale: (768,) (float32)\n",
      "transformer.h.8.mlp.c_fc.bias: (3072,) (float32)\n",
      "transformer.h.8.mlp.c_fc.kernel: (3072, 768) (float32)\n",
      "transformer.h.8.mlp.c_proj.bias: (768,) (float32)\n",
      "transformer.h.8.mlp.c_proj.kernel: (768, 3072) (float32)\n",
      "transformer.h.9.attn.c_attn.bias: (2304,) (float32)\n",
      "transformer.h.9.attn.c_attn.kernel: (2304, 768) (float32)\n",
      "transformer.h.9.attn.c_proj.bias: (768,) (float32)\n",
      "transformer.h.9.attn.c_proj.kernel: (768, 768) (float32)\n",
      "transformer.h.9.ln_1.bias: (768,) (float32)\n",
      "transformer.h.9.ln_1.scale: (768,) (float32)\n",
      "transformer.h.9.ln_2.bias: (768,) (float32)\n",
      "transformer.h.9.ln_2.scale: (768,) (float32)\n",
      "transformer.h.9.mlp.c_fc.bias: (3072,) (float32)\n",
      "transformer.h.9.mlp.c_fc.kernel: (3072, 768) (float32)\n",
      "transformer.h.9.mlp.c_proj.bias: (768,) (float32)\n",
      "transformer.h.9.mlp.c_proj.kernel: (768, 3072) (float32)\n",
      "transformer.ln_f.bias: (768,) (float32)\n",
      "transformer.ln_f.scale: (768,) (float32)\n",
      "transformer.wpe.embedding: (1024, 768) (float32)\n",
      "transformer.wte.embedding: (50257, 768) (float32)\n",
      "\n",
      "üíæ Estimated memory usage: 474.70 MB\n",
      "\n",
      "üî¢ Memory usage by dtype:\n",
      "  float32: 474.70 MB\n",
      "  float16: 237.35 MB\n",
      "  bfloat16: 237.35 MB\n"
     ]
    }
   ],
   "source": [
    "# Inspect JAX/Flax model architecture and parameters\n",
    "import jax\n",
    "from jax.tree_util import tree_map\n",
    "from flax.core import freeze\n",
    "\n",
    "print(\"üîç JAX/Flax Model Inspection\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Basic model info\n",
    "print(f\"Model type: {type(model)}\")\n",
    "print(f\"Model config: {model.config}\")\n",
    "print(f\"Vocab size: {model.config.vocab_size}\")\n",
    "print(f\"Hidden size: {model.config.n_embd}\")\n",
    "print(f\"Number of layers: {model.config.n_layer}\")\n",
    "print(f\"Number of attention heads: {model.config.n_head}\")\n",
    "\n",
    "print(\"\\nüìä Parameter Analysis\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# 2. Count parameters (JAX way)\n",
    "def count_params(params):\n",
    "    \"\"\"Count total parameters in a JAX parameter tree\"\"\"\n",
    "    return sum(x.size for x in jax.tree_util.tree_leaves(params))\n",
    "\n",
    "total_params = count_params(params)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Total parameters (millions): {total_params / 1_000_000:.2f}M\")\n",
    "\n",
    "# 3. Inspect parameter structure\n",
    "print(\"\\nüèóÔ∏è Parameter Structure\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "def print_param_shapes(params, prefix=\"\"):\n",
    "    \"\"\"Recursively print parameter shapes\"\"\"\n",
    "    if isinstance(params, dict):\n",
    "        for key, value in params.items():\n",
    "            print_param_shapes(value, f\"{prefix}.{key}\" if prefix else key)\n",
    "    else:\n",
    "        print(f\"{prefix}: {params.shape} ({params.dtype})\")\n",
    "\n",
    "print_param_shapes(params)\n",
    "\n",
    "# 4. Memory usage estimation\n",
    "def estimate_memory(params):\n",
    "    \"\"\"Estimate memory usage in MB\"\"\"\n",
    "    total_bytes = sum(x.nbytes for x in jax.tree_util.tree_leaves(params))\n",
    "    return total_bytes / (1024 ** 2)\n",
    "\n",
    "memory_mb = estimate_memory(params)\n",
    "print(f\"\\nüíæ Estimated memory usage: {memory_mb:.2f} MB\")\n",
    "\n",
    "# 5. Compare with different dtypes\n",
    "print(f\"\\nüî¢ Memory usage by dtype:\")\n",
    "print(f\"  float32: {memory_mb:.2f} MB\")\n",
    "print(f\"  float16: {memory_mb / 2:.2f} MB\") \n",
    "print(f\"  bfloat16: {memory_mb / 2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0299566c",
   "metadata": {},
   "source": [
    "### Do stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "758829f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 116722 examples from ../data/tldr_train.parquet\n",
      "Loaded 2000 examples from ../data/tldr_valid.parquet\n",
      "üìä Dataset loaded:\n",
      "  Training samples: 116722\n",
      "  Validation samples: 2000\n",
      "\n",
      "üìù Sample data shapes:\n",
      "  input_ids: (550,)\n",
      "  attention_mask: (550,)\n",
      "  labels: (550,)\n",
      "\n",
      "üìã Sample content:\n",
      "  First 100 chars of tokenized text: SUBREDDIT: r/relationships\n",
      "TITLE: I (f/22) have to figure out if I want to still know these girls or...\n",
      "  Input IDs (first 10): [   50 10526 22083 49828    25   374    14 39468  5748   198]\n",
      "  Labels (first 10): [   50 10526 22083 49828    25   374    14 39468  5748   198]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TLDRDataset(\"../data\", tokenizer, split=\"train\")\n",
    "dev_dataset   = TLDRDataset(\"../data\", tokenizer, split=\"valid\")\n",
    "\n",
    "print(f\"üìä Dataset loaded:\")\n",
    "print(f\"  Training samples: {len(train_dataset)}\")\n",
    "print(f\"  Validation samples: {len(dev_dataset)}\")\n",
    "\n",
    "# Preview a sample\n",
    "sample = train_dataset[0]\n",
    "print(f\"\\nüìù Sample data shapes:\")\n",
    "print(f\"  input_ids: {sample['input_ids'].shape}\")\n",
    "print(f\"  attention_mask: {sample['attention_mask'].shape}\")\n",
    "print(f\"  labels: {sample['labels'].shape}\")\n",
    "\n",
    "# Preview actual content\n",
    "print(f\"\\nüìã Sample content:\")\n",
    "print(f\"  First 100 chars of tokenized text: {train_dataset.examples[0][:100]}...\")\n",
    "print(f\"  Input IDs (first 10): {sample['input_ids'][:10]}\")\n",
    "print(f\"  Labels (first 10): {sample['labels'][:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1993ad3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
