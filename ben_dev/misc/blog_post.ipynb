{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1dc63a5",
   "metadata": {},
   "source": [
    "### Define dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932f4c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np  # or jax.numpy as jnp if needed\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "class TLDRDataset:\n",
    "    def __init__(self, data_dir, tokenizer, split, max_length=550):\n",
    "        \"\"\"\n",
    "        Load TLDR dataset from local parquet files.\n",
    "        \n",
    "        Args:\n",
    "            data_dir: Path to directory containing parquet files\n",
    "            tokenizer: Tokenizer to use\n",
    "            split: 'train', 'valid', or 'test'\n",
    "            max_length: Maximum sequence length\n",
    "        \"\"\"\n",
    "        # Load the parquet file\n",
    "        parquet_file = Path(data_dir) / f\"tldr_{split}.parquet\"\n",
    "        if not parquet_file.exists():\n",
    "            raise FileNotFoundError(f\"Dataset file not found: {parquet_file}\")\n",
    "        \n",
    "        df = pd.read_parquet(parquet_file)\n",
    "        \n",
    "        # Combine prompt and label for training (teacher forcing)\n",
    "        self.examples = [row[\"prompt\"] + row[\"label\"] for _, row in df.iterrows()]\n",
    "        \n",
    "        # Limit validation set size for faster iteration\n",
    "        if \"valid\" in split:\n",
    "            self.examples = self.examples[:2000]\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        print(f\"Loaded {len(self.examples)} examples from {parquet_file}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Tokenize the text\n",
    "        enc = self.tokenizer(\n",
    "            self.examples[idx],\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": np.array(enc[\"input_ids\"], dtype=np.int32),\n",
    "            \"attention_mask\": np.array(enc[\"attention_mask\"], dtype=np.int32),\n",
    "            \"labels\": np.array(enc[\"input_ids\"], dtype=np.int32),  # teacher forcing\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43e3ab9",
   "metadata": {},
   "source": [
    "### Load model and tokeniser\n",
    "Stick to gpt2 now for compatibility, then move to qwen. GPT2 = 124m params, 500mb. qwen0.6b = 550m params, 2gb. So beware 3x qwen0.6b on my 8gb gpu might tank its memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22f82951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, FlaxAutoModelForCausalLM\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# 1. Tokenizer is identical\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 2. Load the Flax (JAX) model\n",
    "#    .from_pretrained returns a FlaxAutoModelForCausalLM whose weights live in model.params\n",
    "model = FlaxAutoModelForCausalLM.from_pretrained(\"gpt2\", dtype=jnp.float32)\n",
    "\n",
    "# 3. If you‚Äôve added new tokens, resize just like in PyTorch:\n",
    "#    model = model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# 4. Make sure padding is configured\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# 5. Pull out the parameter dict for training\n",
    "params = model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089f812e",
   "metadata": {},
   "source": [
    "### Inspect model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d4f9d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç JAX/Flax Model Inspection\n",
      "==================================================\n",
      "Model type: <class 'transformers.models.gpt2.modeling_flax_gpt2.FlaxGPT2LMHeadModel'>\n",
      "Model config: GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.53.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "Vocab size: 50257\n",
      "Hidden size: 768\n",
      "Number of layers: 12\n",
      "Number of attention heads: 12\n",
      "\n",
      "üìä Parameter Analysis\n",
      "==============================\n",
      "Total parameters: 124,439,808\n",
      "Total parameters (millions): 124.44M\n",
      "\n",
      "üèóÔ∏è Parameter Structure\n",
      "=========================\n",
      "transformer.h.0.attn.c_attn.bias: (2304,) (float32)\n",
      "transformer.h.0.attn.c_attn.kernel: (2304, 768) (float32)\n",
      "transformer.h.0.attn.c_proj.bias: (768,) (float32)\n",
      "transformer.h.0.attn.c_proj.kernel: (768, 768) (float32)\n",
      "transformer.h.0.ln_1.bias: (768,) (float32)\n",
      "transformer.h.0.ln_1.scale: (768,) (float32)\n",
      "transformer.h.0.ln_2.bias: (768,) (float32)\n",
      "transformer.h.0.ln_2.scale: (768,) (float32)\n",
      "transformer.h.0.mlp.c_fc.bias: (3072,) (float32)\n",
      "transformer.h.0.mlp.c_fc.kernel: (3072, 768) (float32)\n",
      "transformer.h.0.mlp.c_proj.bias: (768,) (float32)\n",
      "transformer.h.0.mlp.c_proj.kernel: (768, 3072) (float32)\n",
      "transformer.h.1.attn.c_attn.bias: (2304,) (float32)\n",
      "transformer.h.1.attn.c_attn.kernel: (2304, 768) (float32)\n",
      "transformer.h.1.attn.c_proj.bias: (768,) (float32)\n",
      "transformer.h.1.attn.c_proj.kernel: (768, 768) (float32)\n",
      "transformer.h.1.ln_1.bias: (768,) (float32)\n",
      "transformer.h.1.ln_1.scale: (768,) (float32)\n",
      "transformer.h.1.ln_2.bias: (768,) (float32)\n",
      "transformer.h.1.ln_2.scale: (768,) (float32)\n",
      "transformer.h.1.mlp.c_fc.bias: (3072,) (float32)\n",
      "transformer.h.1.mlp.c_fc.kernel: (3072, 768) (float32)\n",
      "transformer.h.1.mlp.c_proj.bias: (768,) (float32)\n",
      "transformer.h.1.mlp.c_proj.kernel: (768, 3072) (float32)\n",
      "transformer.h.10.attn.c_attn.bias: (2304,) (float32)\n",
      "transformer.h.10.attn.c_attn.kernel: (2304, 768) (float32)\n",
      "transformer.h.10.attn.c_proj.bias: (768,) (float32)\n",
      "transformer.h.10.attn.c_proj.kernel: (768, 768) (float32)\n",
      "transformer.h.10.ln_1.bias: (768,) (float32)\n",
      "transformer.h.10.ln_1.scale: (768,) (float32)\n",
      "transformer.h.10.ln_2.bias: (768,) (float32)\n",
      "transformer.h.10.ln_2.scale: (768,) (float32)\n",
      "transformer.h.10.mlp.c_fc.bias: (3072,) (float32)\n",
      "transformer.h.10.mlp.c_fc.kernel: (3072, 768) (float32)\n",
      "transformer.h.10.mlp.c_proj.bias: (768,) (float32)\n",
      "transformer.h.10.mlp.c_proj.kernel: (768, 3072) (float32)\n",
      "transformer.h.11.attn.c_attn.bias: (2304,) (float32)\n",
      "transformer.h.11.attn.c_attn.kernel: (2304, 768) (float32)\n",
      "transformer.h.11.attn.c_proj.bias: (768,) (float32)\n",
      "transformer.h.11.attn.c_proj.kernel: (768, 768) (float32)\n",
      "transformer.h.11.ln_1.bias: (768,) (float32)\n",
      "transformer.h.11.ln_1.scale: (768,) (float32)\n",
      "transformer.h.11.ln_2.bias: (768,) (float32)\n",
      "transformer.h.11.ln_2.scale: (768,) (float32)\n",
      "transformer.h.11.mlp.c_fc.bias: (3072,) (float32)\n",
      "transformer.h.11.mlp.c_fc.kernel: (3072, 768) (float32)\n",
      "transformer.h.11.mlp.c_proj.bias: (768,) (float32)\n",
      "transformer.h.11.mlp.c_proj.kernel: (768, 3072) (float32)\n",
      "transformer.h.2.attn.c_attn.bias: (2304,) (float32)\n",
      "transformer.h.2.attn.c_attn.kernel: (2304, 768) (float32)\n",
      "transformer.h.2.attn.c_proj.bias: (768,) (float32)\n",
      "transformer.h.2.attn.c_proj.kernel: (768, 768) (float32)\n",
      "transformer.h.2.ln_1.bias: (768,) (float32)\n",
      "transformer.h.2.ln_1.scale: (768,) (float32)\n",
      "transformer.h.2.ln_2.bias: (768,) (float32)\n",
      "transformer.h.2.ln_2.scale: (768,) (float32)\n",
      "transformer.h.2.mlp.c_fc.bias: (3072,) (float32)\n",
      "transformer.h.2.mlp.c_fc.kernel: (3072, 768) (float32)\n",
      "transformer.h.2.mlp.c_proj.bias: (768,) (float32)\n",
      "transformer.h.2.mlp.c_proj.kernel: (768, 3072) (float32)\n",
      "transformer.h.3.attn.c_attn.bias: (2304,) (float32)\n",
      "transformer.h.3.attn.c_attn.kernel: (2304, 768) (float32)\n",
      "transformer.h.3.attn.c_proj.bias: (768,) (float32)\n",
      "transformer.h.3.attn.c_proj.kernel: (768, 768) (float32)\n",
      "transformer.h.3.ln_1.bias: (768,) (float32)\n",
      "transformer.h.3.ln_1.scale: (768,) (float32)\n",
      "transformer.h.3.ln_2.bias: (768,) (float32)\n",
      "transformer.h.3.ln_2.scale: (768,) (float32)\n",
      "transformer.h.3.mlp.c_fc.bias: (3072,) (float32)\n",
      "transformer.h.3.mlp.c_fc.kernel: (3072, 768) (float32)\n",
      "transformer.h.3.mlp.c_proj.bias: (768,) (float32)\n",
      "transformer.h.3.mlp.c_proj.kernel: (768, 3072) (float32)\n",
      "transformer.h.4.attn.c_attn.bias: (2304,) (float32)\n",
      "transformer.h.4.attn.c_attn.kernel: (2304, 768) (float32)\n",
      "transformer.h.4.attn.c_proj.bias: (768,) (float32)\n",
      "transformer.h.4.attn.c_proj.kernel: (768, 768) (float32)\n",
      "transformer.h.4.ln_1.bias: (768,) (float32)\n",
      "transformer.h.4.ln_1.scale: (768,) (float32)\n",
      "transformer.h.4.ln_2.bias: (768,) (float32)\n",
      "transformer.h.4.ln_2.scale: (768,) (float32)\n",
      "transformer.h.4.mlp.c_fc.bias: (3072,) (float32)\n",
      "transformer.h.4.mlp.c_fc.kernel: (3072, 768) (float32)\n",
      "transformer.h.4.mlp.c_proj.bias: (768,) (float32)\n",
      "transformer.h.4.mlp.c_proj.kernel: (768, 3072) (float32)\n",
      "transformer.h.5.attn.c_attn.bias: (2304,) (float32)\n",
      "transformer.h.5.attn.c_attn.kernel: (2304, 768) (float32)\n",
      "transformer.h.5.attn.c_proj.bias: (768,) (float32)\n",
      "transformer.h.5.attn.c_proj.kernel: (768, 768) (float32)\n",
      "transformer.h.5.ln_1.bias: (768,) (float32)\n",
      "transformer.h.5.ln_1.scale: (768,) (float32)\n",
      "transformer.h.5.ln_2.bias: (768,) (float32)\n",
      "transformer.h.5.ln_2.scale: (768,) (float32)\n",
      "transformer.h.5.mlp.c_fc.bias: (3072,) (float32)\n",
      "transformer.h.5.mlp.c_fc.kernel: (3072, 768) (float32)\n",
      "transformer.h.5.mlp.c_proj.bias: (768,) (float32)\n",
      "transformer.h.5.mlp.c_proj.kernel: (768, 3072) (float32)\n",
      "transformer.h.6.attn.c_attn.bias: (2304,) (float32)\n",
      "transformer.h.6.attn.c_attn.kernel: (2304, 768) (float32)\n",
      "transformer.h.6.attn.c_proj.bias: (768,) (float32)\n",
      "transformer.h.6.attn.c_proj.kernel: (768, 768) (float32)\n",
      "transformer.h.6.ln_1.bias: (768,) (float32)\n",
      "transformer.h.6.ln_1.scale: (768,) (float32)\n",
      "transformer.h.6.ln_2.bias: (768,) (float32)\n",
      "transformer.h.6.ln_2.scale: (768,) (float32)\n",
      "transformer.h.6.mlp.c_fc.bias: (3072,) (float32)\n",
      "transformer.h.6.mlp.c_fc.kernel: (3072, 768) (float32)\n",
      "transformer.h.6.mlp.c_proj.bias: (768,) (float32)\n",
      "transformer.h.6.mlp.c_proj.kernel: (768, 3072) (float32)\n",
      "transformer.h.7.attn.c_attn.bias: (2304,) (float32)\n",
      "transformer.h.7.attn.c_attn.kernel: (2304, 768) (float32)\n",
      "transformer.h.7.attn.c_proj.bias: (768,) (float32)\n",
      "transformer.h.7.attn.c_proj.kernel: (768, 768) (float32)\n",
      "transformer.h.7.ln_1.bias: (768,) (float32)\n",
      "transformer.h.7.ln_1.scale: (768,) (float32)\n",
      "transformer.h.7.ln_2.bias: (768,) (float32)\n",
      "transformer.h.7.ln_2.scale: (768,) (float32)\n",
      "transformer.h.7.mlp.c_fc.bias: (3072,) (float32)\n",
      "transformer.h.7.mlp.c_fc.kernel: (3072, 768) (float32)\n",
      "transformer.h.7.mlp.c_proj.bias: (768,) (float32)\n",
      "transformer.h.7.mlp.c_proj.kernel: (768, 3072) (float32)\n",
      "transformer.h.8.attn.c_attn.bias: (2304,) (float32)\n",
      "transformer.h.8.attn.c_attn.kernel: (2304, 768) (float32)\n",
      "transformer.h.8.attn.c_proj.bias: (768,) (float32)\n",
      "transformer.h.8.attn.c_proj.kernel: (768, 768) (float32)\n",
      "transformer.h.8.ln_1.bias: (768,) (float32)\n",
      "transformer.h.8.ln_1.scale: (768,) (float32)\n",
      "transformer.h.8.ln_2.bias: (768,) (float32)\n",
      "transformer.h.8.ln_2.scale: (768,) (float32)\n",
      "transformer.h.8.mlp.c_fc.bias: (3072,) (float32)\n",
      "transformer.h.8.mlp.c_fc.kernel: (3072, 768) (float32)\n",
      "transformer.h.8.mlp.c_proj.bias: (768,) (float32)\n",
      "transformer.h.8.mlp.c_proj.kernel: (768, 3072) (float32)\n",
      "transformer.h.9.attn.c_attn.bias: (2304,) (float32)\n",
      "transformer.h.9.attn.c_attn.kernel: (2304, 768) (float32)\n",
      "transformer.h.9.attn.c_proj.bias: (768,) (float32)\n",
      "transformer.h.9.attn.c_proj.kernel: (768, 768) (float32)\n",
      "transformer.h.9.ln_1.bias: (768,) (float32)\n",
      "transformer.h.9.ln_1.scale: (768,) (float32)\n",
      "transformer.h.9.ln_2.bias: (768,) (float32)\n",
      "transformer.h.9.ln_2.scale: (768,) (float32)\n",
      "transformer.h.9.mlp.c_fc.bias: (3072,) (float32)\n",
      "transformer.h.9.mlp.c_fc.kernel: (3072, 768) (float32)\n",
      "transformer.h.9.mlp.c_proj.bias: (768,) (float32)\n",
      "transformer.h.9.mlp.c_proj.kernel: (768, 3072) (float32)\n",
      "transformer.ln_f.bias: (768,) (float32)\n",
      "transformer.ln_f.scale: (768,) (float32)\n",
      "transformer.wpe.embedding: (1024, 768) (float32)\n",
      "transformer.wte.embedding: (50257, 768) (float32)\n",
      "\n",
      "üíæ Estimated memory usage: 474.70 MB\n",
      "\n",
      "üî¢ Memory usage by dtype:\n",
      "  float32: 474.70 MB\n",
      "  float16: 237.35 MB\n",
      "  bfloat16: 237.35 MB\n"
     ]
    }
   ],
   "source": [
    "# Inspect JAX/Flax model architecture and parameters\n",
    "import jax\n",
    "from jax.tree_util import tree_map\n",
    "from flax.core import freeze\n",
    "\n",
    "print(\"üîç JAX/Flax Model Inspection\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Basic model info\n",
    "print(f\"Model type: {type(model)}\")\n",
    "print(f\"Model config: {model.config}\")\n",
    "print(f\"Vocab size: {model.config.vocab_size}\")\n",
    "print(f\"Hidden size: {model.config.n_embd}\")\n",
    "print(f\"Number of layers: {model.config.n_layer}\")\n",
    "print(f\"Number of attention heads: {model.config.n_head}\")\n",
    "\n",
    "print(\"\\nüìä Parameter Analysis\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# 2. Count parameters (JAX way)\n",
    "def count_params(params):\n",
    "    \"\"\"Count total parameters in a JAX parameter tree\"\"\"\n",
    "    return sum(x.size for x in jax.tree_util.tree_leaves(params))\n",
    "\n",
    "total_params = count_params(params)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Total parameters (millions): {total_params / 1_000_000:.2f}M\")\n",
    "\n",
    "# 3. Inspect parameter structure\n",
    "print(\"\\nüèóÔ∏è Parameter Structure\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "def print_param_shapes(params, prefix=\"\"):\n",
    "    \"\"\"Recursively print parameter shapes\"\"\"\n",
    "    if isinstance(params, dict):\n",
    "        for key, value in params.items():\n",
    "            print_param_shapes(value, f\"{prefix}.{key}\" if prefix else key)\n",
    "    else:\n",
    "        print(f\"{prefix}: {params.shape} ({params.dtype})\")\n",
    "\n",
    "print_param_shapes(params)\n",
    "\n",
    "# 4. Memory usage estimation\n",
    "def estimate_memory(params):\n",
    "    \"\"\"Estimate memory usage in MB\"\"\"\n",
    "    total_bytes = sum(x.nbytes for x in jax.tree_util.tree_leaves(params))\n",
    "    return total_bytes / (1024 ** 2)\n",
    "\n",
    "memory_mb = estimate_memory(params)\n",
    "print(f\"\\nüíæ Estimated memory usage: {memory_mb:.2f} MB\")\n",
    "\n",
    "# 5. Compare with different dtypes\n",
    "print(f\"\\nüî¢ Memory usage by dtype:\")\n",
    "print(f\"  float32: {memory_mb:.2f} MB\")\n",
    "print(f\"  float16: {memory_mb / 2:.2f} MB\") \n",
    "print(f\"  bfloat16: {memory_mb / 2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0299566c",
   "metadata": {},
   "source": [
    "### Do stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "758829f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 116722 examples from ../data/tldr_train.parquet\n",
      "Loaded 2000 examples from ../data/tldr_valid.parquet\n",
      "üìä Dataset loaded:\n",
      "  Training samples: 116722\n",
      "  Validation samples: 2000\n",
      "\n",
      "üìù Sample data shapes:\n",
      "  input_ids: (550,)\n",
      "  attention_mask: (550,)\n",
      "  labels: (550,)\n",
      "\n",
      "üìã Sample content:\n",
      "  First 100 chars of tokenized text: SUBREDDIT: r/relationships\n",
      "TITLE: I (f/22) have to figure out if I want to still know these girls or...\n",
      "  Input IDs (first 10): [   50 10526 22083 49828    25   374    14 39468  5748   198]\n",
      "  Labels (first 10): [   50 10526 22083 49828    25   374    14 39468  5748   198]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TLDRDataset(\"../data\", tokenizer, split=\"train\")\n",
    "val_dataset   = TLDRDataset(\"../data\", tokenizer, split=\"valid\")\n",
    "\n",
    "print(f\"üìä Dataset loaded:\")\n",
    "print(f\"  Training samples: {len(train_dataset)}\")\n",
    "print(f\"  Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "# Preview a sample\n",
    "sample = train_dataset[0]\n",
    "print(f\"\\nüìù Sample data shapes:\")\n",
    "print(f\"  input_ids: {sample['input_ids'].shape}\")\n",
    "print(f\"  attention_mask: {sample['attention_mask'].shape}\")\n",
    "print(f\"  labels: {sample['labels'].shape}\")\n",
    "\n",
    "# Preview actual content\n",
    "print(f\"\\nüìã Sample content:\")\n",
    "print(f\"  First 100 chars of tokenized text: {train_dataset.examples[0][:100]}...\")\n",
    "print(f\"  Input IDs (first 10): {sample['input_ids'][:10]}\")\n",
    "print(f\"  Labels (first 10): {sample['labels'][:10]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cc33c5",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c36207a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Creating data loaders...\n",
      "üì¶ Testing batch loading...\n",
      "Batch shapes:\n",
      "  input_ids: (4, 550)\n",
      "  attention_mask: (4, 550)\n",
      "  labels: (4, 550)\n",
      "  Data type: int32\n",
      "\n",
      "üìä Batch counts:\n",
      "  Training batches: 29181\n",
      "  Validation batches: 500\n",
      "\n",
      "‚úÖ Data loader ready for JAX training!\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "\n",
    "def create_data_loader(dataset, batch_size, shuffle=True, key=None):\n",
    "    \"\"\"\n",
    "    Simple data loader for JAX training.\n",
    "    \n",
    "    Args:\n",
    "        dataset: TLDRDataset instance\n",
    "        batch_size: Number of samples per batch\n",
    "        shuffle: Whether to shuffle the data\n",
    "        key: JAX random key for shuffling\n",
    "    \n",
    "    Returns:\n",
    "        Generator yielding batches of data\n",
    "    \"\"\"\n",
    "    if key is None:\n",
    "        key = random.PRNGKey(42)\n",
    "    \n",
    "    num_samples = len(dataset)\n",
    "    indices = jnp.arange(num_samples)\n",
    "    \n",
    "    # Shuffle indices if requested\n",
    "    if shuffle:\n",
    "        key, subkey = random.split(key)\n",
    "        indices = random.permutation(subkey, num_samples)\n",
    "\n",
    "    # Generate batches\n",
    "    for start_idx in range(0, num_samples, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, num_samples)\n",
    "        batch_indices = indices[start_idx:end_idx]\n",
    "        \n",
    "        # Collect batch data\n",
    "        batch_data = {\n",
    "            \"input_ids\": [],\n",
    "            \"attention_mask\": [],\n",
    "            \"labels\": []\n",
    "        }\n",
    "\n",
    "        # Iterate over selected indices to gather batch\n",
    "        for idx in batch_indices:\n",
    "            sample = dataset[int(idx)]\n",
    "            batch_data[\"input_ids\"].append(sample[\"input_ids\"])\n",
    "            # I think our mask pads to the left, so: <pad>, <pad>, <pad>, \"hello\", \"world\"\n",
    "            batch_data[\"attention_mask\"].append(sample[\"attention_mask\"])\n",
    "            batch_data[\"labels\"].append(sample[\"labels\"])\n",
    "        \n",
    "        # Convert to JAX arrays\n",
    "        yield {\n",
    "            \"input_ids\": jnp.array(batch_data[\"input_ids\"]),\n",
    "            \"attention_mask\": jnp.array(batch_data[\"attention_mask\"]),\n",
    "            \"labels\": jnp.array(batch_data[\"labels\"])\n",
    "        }\n",
    "\n",
    "# Example usage\n",
    "print(\"üîÑ Creating data loaders...\")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 4  # Small batch for demo\n",
    "train_key = random.PRNGKey(0)\n",
    "val_key = random.PRNGKey(1)\n",
    "\n",
    "train_loader = create_data_loader(train_dataset, batch_size, shuffle=True, key=train_key)\n",
    "val_loader = create_data_loader(val_dataset, batch_size, shuffle=False, key=val_key)\n",
    "\n",
    "# Test the data loader\n",
    "print(\"üì¶ Testing batch loading...\")\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "print(f\"Batch shapes:\")\n",
    "print(f\"  input_ids: {batch['input_ids'].shape}\")\n",
    "print(f\"  attention_mask: {batch['attention_mask'].shape}\")\n",
    "print(f\"  labels: {batch['labels'].shape}\")\n",
    "print(f\"  Data type: {batch['input_ids'].dtype}\")\n",
    "\n",
    "# Show how many batches we'll have\n",
    "train_batches = (len(train_dataset) + batch_size - 1) // batch_size\n",
    "val_batches = (len(val_dataset) + batch_size - 1) // batch_size\n",
    "print(f\"\\nüìä Batch counts:\")\n",
    "print(f\"  Training batches: {train_batches}\")\n",
    "print(f\"  Validation batches: {val_batches}\")\n",
    "\n",
    "print(\"\\n‚úÖ Data loader ready for JAX training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98d3257a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   50, 10526, 22083, 49828,    25,   374,    14, 25214, 22367,\n",
       "         198, 49560,  2538,    25,  1374,   466,   345,   651,  2130,\n",
       "         503,   286,   534,  1182,    30,   198, 32782,    25, 15902,\n",
       "          11,   198,    40,  1101,  2534,    11,   290,   314,   423,\n",
       "         587,   351,   616, 11077,   329,   642,   812,   783,    13,\n",
       "         775,  2904,  3888,  1978,    13,   775,  1053,  1464,  6151,\n",
       "        1123,   584, 31146,    13,   198,   198, 40781,    11,   314,\n",
       "        2904,  2067,   284,   423,  7666,   329,   281,   584,  1048,\n",
       "         357,    64,  1545,   737,   770,  1048,   468,   550,   257,\n",
       "       13850,   329,   783,   513,   812,    11,   290,   468,  5543,\n",
       "         645,  4213,    13,  5845,  7666,   547,   523,  1913,    11,\n",
       "         340,   373,  1327,   284,  7808,   606,    13,  2293,   362,\n",
       "        1933,   286,   502,   852, 12899,   290,  1107,  6507,    11,\n",
       "         616, 11077,  4137,   502,   284,   910,   644,   373, 41656,\n",
       "         502,    13,   314,  1101,   407,   257,   922, 31866,    11,\n",
       "         290,   783,   673,  4206,    13,   198,   198,  1135,  3066,\n",
       "         284,  1577,   514,   257,  1285,  3436,    11,   314,  1816,\n",
       "         284,   616,  3397,    13,   220,   198,   198,  3844,    11,\n",
       "         314,  1101,  3190,  2626,    13,   314,  1394,   319,  3612,\n",
       "         546,   428,  1048,    11,   290,   314,  5465,   326,    13,\n",
       "         314,   561,   588,   329,   883,  7666,   284,   467,  1497,\n",
       "          11,   284,  2666,   502,  3436,    13,   887,   314,   460,\n",
       "         470,    13,   220,   220,   198,   198,  2061,   466,   314,\n",
       "         466,    30,   632,   338,   587,   513,  1933,   783,    11,\n",
       "         290,   314,  1101,   655, 12111,    13,   198, 14990,    26,\n",
       "        7707,    25,   890,  2776,    26,  3214,   287,  1842,   351,\n",
       "         281,   584,  1048,    26,  6848,   340,    26,   561,   588,\n",
       "         340,   284, 10921,    11,   996,   340,  1595,   470,    13,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "       50256], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[int(0)][\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d75bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
